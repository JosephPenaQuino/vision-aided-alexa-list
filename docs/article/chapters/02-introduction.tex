\section{Introduction}

In recent years, the convenience of mini-markets within residential complexes has become increasingly prevalent, providing residents with easy access to daily necessities just steps away from their homes. This model, often referred to as proximity retailing, has been lauded for enhancing convenience without the need for traditional delivery services or trips to larger supermarkets \cite{smith2020}. Concurrently, voice assistants such as Amazon Alexa have become integral to the smart home ecosystem, helping users manage tasks like shopping lists through voice commands \cite{jones2019}.

While previous studies have explored the role of voice assistants in domestic environments, particularly in organizing and automating household activities, few have examined their integration with visual recognition technologies for retail applications. Virtual assistants, like Alexa, have been recognized for their ability to facilitate daily tasks and enhance user convenience \cite{doe2021}. However, the combination of voice technology with computer vision remains underexplored, particularly in smaller-scale retail environments, such as neighborhood mini-markets \cite{lee2020}.

Recent advancements in artificial intelligence (AI) and cloud-based services have paved the way for innovative applications in retail. Vision-aided systems, for instance, have proven highly effective in automating inventory management and improving product identification \cite{wang2022}. These technologies, often powered by services like AWS Rekognition, enable real-time visual analysis, allowing for the seamless recognition of products based on visual inputs. Despite the potential of such systems, there remains a gap in the literature regarding their use alongside voice assistants in localized retail contexts \cite{chen2023}.

This paper addresses this gap by proposing a system in which Alexaâ€™s list management capabilities are augmented with vision-based recognition. Using AWS Rekognition for image processing, AWS Lambda for computation, and AWS DynamoDB for data storage, we enable Alexa to automatically update shopping lists based on the available products in mini-markets. This approach enhances the shopping experience by bridging the gap between the virtual and physical worlds, allowing users to interact with their environment in a more seamless and intuitive manner.

The contributions of this work are threefold: (1) the development of a vision-aided shopping list system integrated with Alexa, (2) the use of AWS cloud services to implement real-time product recognition, and (3) the enhancement of the smart home ecosystem through the integration of virtual assistants with localized retail inventories. This research demonstrates the potential of combining voice and vision technologies to create a more efficient and user-friendly retail experience.

The remainder of this paper is structured as follows: Section 2 outlines the methodology used for the system implementation, detailing the integration of AWS services and Alexa Skills. Section 3 presents the results of the general integration test of the system evaluated in a basic, medium and advanced difficulty scenarion. Finally, Section 4 concludes with an evaluation of the system's performance and potential future improvements.